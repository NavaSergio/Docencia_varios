---
title: "Calidad y Limpieza de Datos en Ciencia de Datos"
author: "Profesor de Ciencia de Datos"
date: today
format: revealjs
theme: solarized
transition: slide
highlight-style: github
---

## Introducción

- La calidad de los datos es fundamental en la investigación y la ciencia de datos.
- Los datos suelen contener errores, valores atípicos y problemas estructurales.
- Antes de realizar cualquier análisis, es crucial validar y limpiar los datos.

---

## Objetivos de la Presentación

1. Comprender la importancia de la limpieza de datos.
2. Identificar los errores más comunes en datasets.
3. Aprender técnicas prácticas de exploración y validación de datos.
4. Conocer en profundidad la validación de supuestos estadísticos y el manejo de datos faltantes.

---

## **Parte 1: ¿Por qué es importante la limpieza de datos?** 

- **Mito de la Robustez:** No todos los métodos estadísticos son robustos a violaciones de supuestos.
- **Errores comunes en la literatura científica:**  
  - Falta de validación de supuestos estadísticos.
  - Falta de reporte de pruebas de normalidad y homogeneidad de varianza.
  - Uso erróneo de métricas sin verificar su significado.
- **Impacto en la replicabilidad de estudios científicos.**

---

## **Parte 2: Evaluación de la Estructura de Datos**

- Tipos de formatos comunes:
  - **CSV (Comma-Separated Values)**
  - **JSON (JavaScript Object Notation)**
  - **XML (Extensible Markup Language)**
  - **Excel (XLS, XLSX)**
- Técnicas para interpretar la estructura:
  - Inspeccionar cabeceras y delimitadores.
  - Verificar la presencia de nombres de columnas y etiquetas.

---

## **Parte 3: Validación de Supuestos Estadísticos** {.scrollable}

Los métodos estadísticos dependen de ciertos supuestos sobre los datos. Antes de realizar análisis, debemos validar:

1. **Normalidad**  
   - Muchos métodos asumen que los datos siguen una distribución normal.
   - Se puede evaluar con pruebas estadísticas (Shapiro-Wilk, Kolmogorov-Smirnov) o gráficamente (histogramas, Q-Q plots).

2. **Homogeneidad de varianza**  
   - Métodos como ANOVA requieren que las varianzas de los grupos sean similares.
   - Se puede evaluar con pruebas como Levene o Bartlett.

3. **Independencia de los datos**  
   - La independencia de las observaciones es crítica en modelos de regresión y ANOVA.
   - Se puede evaluar revisando la estructura del diseño del estudio o con pruebas estadísticas como la de Durbin-Watson en series temporales.

4. **Ausencia de multicolinealidad**  
   - En regresión múltiple, la alta correlación entre variables predictoras puede distorsionar los coeficientes.
   - Se evalúa con el Factor de Inflación de Varianza (VIF).

5. **Linealidad**  
   - En regresión, la relación entre variables debe ser lineal.
   - Se puede verificar visualmente con gráficos de dispersión.

---

## **Parte 4: Manejo de Datos Faltantes** {.scrollable}

Los datos faltantes pueden distorsionar análisis y modelos. Existen distintos enfoques para manejarlos:

1. **Tipos de Datos Faltantes**
   - **MCAR (Missing Completely at Random)**: La falta de datos no está relacionada con ninguna variable del estudio.
   - **MAR (Missing at Random)**: La falta de datos depende de otras variables observadas.
   - **MNAR (Missing Not at Random)**: La ausencia de datos está relacionada con el valor en sí mismo.

2. **Estrategias de Manejo de Datos Faltantes**
   - **Eliminación de Filas o Columnas**  
     - Útil si la cantidad de datos faltantes es pequeña.
     - No recomendable si se pierde demasiada información.
   - **Imputación de Valores**  
     - **Media/Mediana**: Rellena valores con la media o mediana del conjunto de datos.
     - **Interpolación**: Usa valores adyacentes para estimar los datos faltantes (útil en series temporales).
     - **Modelos Predictivos**: Se pueden usar regresiones o algoritmos de machine learning (KNN, árboles de decisión).
   - **Métodos Basados en Múltiples Imputaciones**  
     - Genera varias imputaciones para reflejar la incertidumbre sobre los valores reales.
     - Métodos como MICE (Multivariate Imputation by Chained Equations) son ampliamente usados.

3. **Impacto de los Datos Faltantes en Modelos**  
   - La eliminación de datos puede sesgar los resultados.
   - La imputación inadecuada puede reducir la varianza artificialmente.
   - Siempre se deben reportar las estrategias usadas para manejar datos faltantes.

---

## **Parte 5: Estadísticas Descriptivas y Validación Numérica**

- **Medidas clave para detectar anomalías:**
  - **Mínimo y máximo:** Detecta valores fuera de rango.
  - **Media y mediana:** Evalúa el centro de la distribución.
  - **Desviación estándar:** Identifica dispersión anormal.
  - **Histogramas y gráficos de caja:** Muestran patrones inusuales.

---

## **Parte 6: Visualización para la Calidad de Datos**

- **Histogramas:** Para entender distribuciones y valores atípicos.
- **Gráficos de series temporales:** Para detectar patrones estacionales o datos faltantes.
- **Ejemplo de outliers en datos financieros:**  
  - En datos de publicidad digital (PPC), una brecha en valores puede indicar errores en la recopilación.

---

## **Parte 7: Series Temporales y Detección de Errores**

- **Ejemplo: Datos de Wikipedia**
  - Detectar días con valores inusuales en tráfico web.
  - Identificar días con datos duplicados o faltantes.

---

## **Conclusiones**

- **La limpieza de datos NO es opcional.**
- Validar datos con inspección manual y análisis estadístico.
- Usar herramientas adecuadas para detectar errores en datos estructurados y series temporales.
- Reportar siempre los procesos de limpieza y validación en los estudios científicos.

---

## **Referencias**

- Osborne, J.W. (2008). *Best Practices in Data Cleaning*.
- Fink, K. (2012). *Bad Data Handbook*.
- Keselman, H.J. et al. (1998). "Statistical Practices of Educational Researchers".
- Vardeman & Morris (2003). *Statistics and Ethics*.

---

## **Preguntas y Discusión**
